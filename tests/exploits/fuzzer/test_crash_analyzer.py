"""Tests for crash analyzer module."""

import pytest
import tempfile
from pathlib import Path
from exploits.fuzzer.crash_analyzer import CrashAnalyzer


class TestCrashAnalyzer:
    """Test suite for CrashAnalyzer class."""

    @pytest.fixture
    def analyzer(self):
        """Create a crash analyzer instance."""
        return CrashAnalyzer()

    @pytest.fixture
    def temp_dir(self):
        """Create a temporary directory."""
        with tempfile.TemporaryDirectory() as tmpdir:
            yield tmpdir

    @pytest.fixture
    def sample_crashes(self, temp_dir):
        """Create sample crash files."""
        crash_dir = Path(temp_dir) / "crashes"
        crash_dir.mkdir()

        # Different types of crashes
        crashes = {
            "buffer_overflow": b"A" * 1000,
            "format_string": b"%s%s%s%s%s%n%n%n",
            "null_deref": b"\x00" * 64,
            "heap_overflow": b"H" * 2048,
            "stack_overflow": b"S" * 10000
        }

        for name, data in crashes.items():
            (crash_dir / f"{name}.crash").write_bytes(data)

        return str(crash_dir)

    def test_analyzer_initialization(self, analyzer):
        """Test analyzer initializes correctly."""
        assert analyzer is not None
        assert hasattr(analyzer, 'analyze_crash_file')
        assert hasattr(analyzer, 'analyze_directory')
        assert hasattr(analyzer, 'calculate_exploitability')

    def test_analyze_empty_directory(self, analyzer, temp_dir):
        """Test analysis of empty directory."""
        crash_dir = Path(temp_dir) / "empty_crashes"
        crash_dir.mkdir()

        results = analyzer.analyze_directory(str(crash_dir))
        assert isinstance(results, list)
        assert len(results) == 0

    def test_analyze_directory(self, analyzer, sample_crashes):
        """Test analysis of directory with crashes."""
        results = analyzer.analyze_directory(sample_crashes)

        assert isinstance(results, list)
        assert len(results) == 5

        for crash in results:
            assert 'file' in crash
            assert 'size' in crash
            assert 'hash' in crash
            assert 'exploitability' in crash

    def test_crash_deduplication(self, analyzer, temp_dir):
        """Test that analyzer deduplicates identical crashes."""
        crash_dir = Path(temp_dir) / "crashes"
        crash_dir.mkdir()

        # Create duplicate crashes
        data = b"DUPLICATE_CRASH"
        (crash_dir / "crash1.txt").write_bytes(data)
        (crash_dir / "crash2.txt").write_bytes(data)
        (crash_dir / "crash3.txt").write_bytes(b"DIFFERENT")

        results = analyzer.analyze_directory(str(crash_dir))

        # Get unique hashes
        unique_hashes = set(r['hash'] for r in results)
        assert len(unique_hashes) == 2

    def test_calculate_exploitability_high(self, analyzer):
        """Test exploitability calculation for likely exploitable crash."""
        crash_data = b"A" * 1000  # Buffer overflow pattern

        exploitability = analyzer.calculate_exploitability(
            crash_data=crash_data,
            crash_type='buffer_overflow'
        )

        assert exploitability in ['high', 'medium', 'low', 'unknown']

    def test_calculate_exploitability_patterns(self, analyzer):
        """Test exploitability based on various patterns."""
        patterns = {
            b"A" * 1000: 'buffer_overflow',
            b"%s%n%n": 'format_string',
            b"\x00" * 64: 'null_dereference',
        }

        for data, expected_type in patterns.items():
            result = analyzer.calculate_exploitability(
                crash_data=data,
                crash_type=expected_type
            )
            assert result in ['high', 'medium', 'low', 'unknown']

    def test_detect_crash_type(self, analyzer):
        """Test crash type detection."""
        # Buffer overflow
        crash_type = analyzer.detect_crash_type(b"A" * 1000)
        assert crash_type in ['buffer_overflow', 'unknown']

        # Format string
        crash_type = analyzer.detect_crash_type(b"%s%s%n")
        assert crash_type in ['format_string', 'unknown']

    def test_analyze_crash_file(self, analyzer, temp_dir):
        """Test analysis of individual crash file."""
        crash_file = Path(temp_dir) / "test.crash"
        crash_file.write_bytes(b"CRASH_DATA")

        result = analyzer.analyze_crash_file(str(crash_file))

        assert isinstance(result, dict)
        assert result['file'] == str(crash_file)
        assert 'size' in result
        assert 'hash' in result
        assert 'exploitability' in result
        assert 'crash_type' in result

    def test_hash_calculation(self, analyzer):
        """Test crash hash calculation."""
        data1 = b"CRASH_DATA"
        data2 = b"CRASH_DATA"
        data3 = b"DIFFERENT"

        hash1 = analyzer.calculate_hash(data1)
        hash2 = analyzer.calculate_hash(data2)
        hash3 = analyzer.calculate_hash(data3)

        assert hash1 == hash2
        assert hash1 != hash3

    def test_exploitability_scoring(self, analyzer):
        """Test exploitability scoring system."""
        # High exploitability signals
        high_signals = {
            'crash_type': 'buffer_overflow',
            'stack_canary_bypass': True,
            'rip_control': True
        }

        score = analyzer.score_exploitability(high_signals)
        assert score >= 7  # Should be high

        # Low exploitability signals
        low_signals = {
            'crash_type': 'null_dereference',
            'stack_canary_bypass': False,
            'rip_control': False
        }

        score = analyzer.score_exploitability(low_signals)
        assert score <= 5  # Should be low to medium

    def test_identify_interesting_crashes(self, analyzer, sample_crashes):
        """Test identification of interesting crashes."""
        results = analyzer.analyze_directory(sample_crashes)
        interesting = analyzer.filter_interesting(results)

        assert isinstance(interesting, list)
        # Interesting crashes should have exploitability scores
        for crash in interesting:
            assert crash['exploitability'] in ['high', 'medium']

    def test_generate_crash_report(self, analyzer, sample_crashes):
        """Test crash report generation."""
        results = analyzer.analyze_directory(sample_crashes)
        report = analyzer.generate_report(results)

        assert isinstance(report, dict)
        assert 'total_crashes' in report
        assert 'unique_crashes' in report
        assert 'by_exploitability' in report
        assert 'by_crash_type' in report

    def test_empty_crash_file(self, analyzer, temp_dir):
        """Test handling of empty crash file."""
        crash_file = Path(temp_dir) / "empty.crash"
        crash_file.write_bytes(b"")

        result = analyzer.analyze_crash_file(str(crash_file))
        assert result['size'] == 0

    def test_large_crash_file(self, analyzer, temp_dir):
        """Test handling of large crash file."""
        crash_file = Path(temp_dir) / "large.crash"
        crash_file.write_bytes(b"X" * 1000000)  # 1MB

        result = analyzer.analyze_crash_file(str(crash_file))
        assert result['size'] == 1000000

    def test_binary_crash_data(self, analyzer, temp_dir):
        """Test handling of binary crash data."""
        crash_file = Path(temp_dir) / "binary.crash"
        crash_file.write_bytes(b"\x00\x01\x02\xff\xfe\xfd")

        result = analyzer.analyze_crash_file(str(crash_file))
        assert 'hash' in result

    def test_crash_similarity(self, analyzer):
        """Test crash similarity detection."""
        crash1 = b"A" * 100
        crash2 = b"A" * 101
        crash3 = b"B" * 100

        similarity_1_2 = analyzer.calculate_similarity(crash1, crash2)
        similarity_1_3 = analyzer.calculate_similarity(crash1, crash3)

        # Similar crashes should have higher similarity
        assert similarity_1_2 > similarity_1_3

    def test_prioritize_crashes(self, analyzer, sample_crashes):
        """Test crash prioritization."""
        results = analyzer.analyze_directory(sample_crashes)
        prioritized = analyzer.prioritize_crashes(results)

        assert isinstance(prioritized, list)
        # Should be sorted by exploitability/priority
        if len(prioritized) > 1:
            assert prioritized[0]['priority'] >= prioritized[-1]['priority']

    def test_extract_crash_context(self, analyzer):
        """Test extraction of crash context information."""
        crash_data = b"A" * 200 + b"INJECTION_POINT" + b"B" * 200

        context = analyzer.extract_context(crash_data)

        assert isinstance(context, dict)
        assert 'length' in context
        assert 'patterns' in context

    def test_exploit_mitigation_detection(self, analyzer):
        """Test detection of exploit mitigations."""
        # Simulate crash with mitigation info
        mitigations = analyzer.detect_mitigations(
            crash_info={'stack_canary': True, 'nx': True, 'aslr': True}
        )

        assert isinstance(mitigations, dict)
